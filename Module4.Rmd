---
title: "Module 4 Report"
author: '450132759 / 450463055'
date: "October 31, 2018"
output: 
  prettydoc::html_pretty:
    theme: cayman # prettydoc theme
    highlight: null # syntax highlighting
    css: custom.css # custom css file to change font family and size
---
<!-- <style> -->
<!-- @import url('https://fonts.googleapis.com/css?family=Roboto+Mono'); -->
<!-- @import url('https://fonts.googleapis.com/css?family=Lato'); -->
<!-- body{ -->
<!--   font-family: 'Lato' !important; -->
<!--   font-size: 12pt; -->
<!-- } -->

<!-- code{ -->
<!--   font-family: 'Roboto Mono' !important; -->
<!--   font-size: 12px; -->
<!-- } -->

<!-- pre{ -->
<!--   font-family: 'Roboto Mono' !important; -->
<!--   font-size: 12px -->
<!-- } -->

<!-- td{ -->
<!--   font-family: Lato !important; -->
<!--   font-size: 12pt; -->
<!-- } -->
<!-- </style> -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.align = "center")
```

## Executive Summary
In this report, we use various machine learning algorithms to make a prediction on whether an email is flagged as spam or nonspam. It is found that a binomial logistic model gives the best accuracy, followed by a decision tree model, and then a k-nearest neighbour model.
## Analysis

```{r import}
library(tidyverse)
library(gridExtra)
library(emmeans)
library(ggfortify)
# install.packages('kernlab')
data(spam, package = "kernlab")
```

```{r cleaning}
spam <- spam %>% mutate(type = ifelse(type == "spam", 1, 0))
spam$type = as.factor(spam$type)
```
Here, we changed 


### Decision Tree
```{r}
#install.packages("rpart")
#install.packages("rpart.plot")
library(rpart)
library(rpart.plot)
tree = rpart(factor(type) ~ ., data = spam, method = "class")
rpart.plot(tree)
```

```{r in.sample}
library(caret)
predicted = predict(tree, type = "class")
confusionMatrix(
  data = predicted,
  reference = factor(spam$type),
  positive = "1")
```
In sample performance of decision tree model gives an accuracy of 90.26%. We also observe a specificity value of 0.9519 and a sensitivity value of 0.8268. The high specificity value is especially desirable in this case, as it indicates a low falso positive rate. This means that clean emails are rarely classified as spam.

```{r complexity}
train(type ~ ., data = spam,
     method = "rpart", trControl = trainControl(method = "cv", number = 10))
```
Above, we look at finding the complexity parameter that gives the least RMSE, which is cp = 0.0430, around 4.3%. The complexity parameter gives an out of sample accuracy of about 85.7%.


### Random Forest

Now, we look to fit a random forest model. 
```{r randomforest}
library(randomForest)
tree_rf = randomForest(type ~ ., spam)
tree_rf
```
We observe an insample error of about 4.48%, which translate to an accuracy of about 95.52%. This is better than the observed accuracy from the decision tree model.

### Logistic Regression
Here, we seek to fit a binomial logistic model. We find a suitable model using backwards and forwards AIC.

```{r logistic_regression, cache=TRUE, results='hide'}
# install.packages("stargazer")
# library(stargazer)
spam_full_glm <- glm(type ~ ., family = binomial, data = spam)
spam_bw_aic = step(spam_full_glm,direction = "backward",trace=TRUE)
spam_null_glm <- glm(type ~ 1, family = binomial, data = spam)
spam_fw_aic = step(spam_full_glm,direction = "forward",trace=TRUE)
```

```{r log_regree_performance}

spam = spam %>% mutate(pred_bw = predict(spam_bw_aic, type = "response"),
         pred_bw = round(pred_bw))

mean(spam$type != spam$pred_bw)
library(caret)
confusion.glm = confusionMatrix(
  data = as.factor(spam$pred_bw), 
  reference = as.factor(spam$type),
  positive = "1")
confusion.glm
# stargazer::stargazer(fm, step_model, type = "html", column.labels = c("Full model",
    # "Stepwise model"))

spam = spam %>% mutate(pred_fw = predict(spam_fw_aic, type = "response"),
         pred_fw = round(pred_fw))

mean(spam$type != spam$pred_fw)
library(caret)
confusion.glm = confusionMatrix(
  data = as.factor(spam$pred_fw), 
  reference = as.factor(spam$type),
  positive = "1")
confusion.glm

# train(spam_bw_aic,
#       data = spam, 
#       method = "glm",
#       family = "binomial",
#       trControl = trainControl(
#         method = "cv", number = 5,
#         verboseIter = FALSE
#       ))
```
We observe a 93% accuracy from the backwards AIC logistic model.

### Nearest Neighbour
```{r in.sample.5, cache = TRUE}
knn5 = class::knn(train = spam, test = spam, cl = spam$type, k = 5)
confusionMatrix(knn5, spam$type, positive = "1")
caret::confusionMatrix(knn5, spam$type)$table
caret::confusionMatrix(knn5, spam$type)$overall[1] %>% round(2)
```
Here, we observe a specificity of 91.07%. 
```{r out.of.sample, cache = TRUE}
fitControl = trainControl(method = "repeatedcv", number = 5, repeats = 10)
knnFit1 = train(type ~ ., data = spam, method = "knn", trControl = fitControl, 
    tuneLength = 10)
knnFit1
```

```{r, warning=TRUE}
# knn_acc = max(knnFit1$results$Accuracy)
# # decision tree
# rpartFit1 = train(type ~ ., data = spam, method = "rpart", trControl = fitControl)
# rpart_acc = max(rpartFit1$results$Accuracy)
# rpart_acc
# # random forests
# rfFit1 = train(type ~ ., data = spam, method = "rf", trControl = fitControl)
# rf_acc = max(rfFit1$results$Accuracy)
# # glm
# glmFit1 = train(type ~ ., data = spam, method = "glm", family = "binomial",
#     trControl = fitControl)
# glm_acc = glmFit1$results$Accuracy
# knn_acc
# glm_acc
```



##Conclusion
